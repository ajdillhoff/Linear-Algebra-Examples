{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81277640",
   "metadata": {},
   "source": [
    "# Eigenfaces\n",
    "\n",
    "Principal Component Analysis captures the variance of a set of data in a very convenient form. In this notebook, you will implement Eigenfaces: a facial recognition framework based on PCA. The idea is that the most important variances will be represented by the eigenvectors of the covariance matrix of faces.\n",
    "\n",
    "## Loading the Data\n",
    "\n",
    "The first task is to load and visualize the data. Luckily, code has already been provided for this. You will need to change `data_dir` to point to the location of the extracted dataset that was downloaded from Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb91a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw images\n",
    "data_dir = \"/home/alex/Downloads/ATTfaces/faces/\"\n",
    "file_names = os.listdir(data_dir)\n",
    "images = [np.asarray(Image.open(data_dir + file_names[i])) for i in range(len(file_names))]\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc996ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the faces\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(8, 8), axes_pad=0)\n",
    "\n",
    "for ax, im in zip(grid, images[:64]):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d2f14",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Eigenfaces is a technique based on PCA that allows for image compression, face detection, and face recognition. In this assignment, you will be filling in the relevant code to view how images are reconstructed using the eigenfaces.\n",
    "\n",
    "This method is implemented in the following steps:\n",
    "1. Compute the mean face image of your dataset. This can be done simply via `numpy`.\n",
    "2. Compute the eigenfaces (eigenvectors) of your dataset. There are two ways to accomplish this that we have covered in class. The first option is to use SVD. The $U$ matrix represents the normalized eigenvectors. A second option is to perform eigendecomposition on the covariance matrix. This method is detailed below.\n",
    "3. Finally, the weights for each image are calculated. These weights indicate how much of each principle component contribute to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ff397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean face\n",
    "# face_mean = # TODO: Fill in the code to get the mean face image\n",
    "face_mean = images.mean(0)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(face_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2637d",
   "metadata": {},
   "source": [
    "# Performing Eigendecomposition\n",
    "\n",
    "There are 400 images with resolution 92 x 112. To calculate a covariance matrix, you'll need to reshape the images so that each one is a 10304-dimensional vector. This covariance matrix is divided by 1 less than the number of samples:\n",
    "\n",
    "\\begin{equation*}\n",
    "C = \\frac{1}{n-1} X^T X\n",
    "\\end{equation*}\n",
    "\n",
    "Now we can easily compute a covariance matrix, right?\n",
    "\n",
    "## Computational Complexity of $X^T X$\n",
    "\n",
    "The covariance matrix of a dataset with 10304 features will be $10304 \\times 10304$. This will take a long time to compute. **Instead, we will compute the covariance matrix of the 400 samples. This yields a $400 \\times 400$ matrix.**\n",
    "\n",
    "**How do the eigenvectors of the $400 \\times 400$ covariance matrix relate to the $10304 \\times 10304$ matrix?**\n",
    "\n",
    "Let $X \\in \\mathbb{R}^{10304 \\times 400}$. Then $P = X^T X \\in \\mathbb{R}^{400 \\times 400}$ and $C = X X^T \\in \\mathbb{R}^{10304 \\times 10304}$. If $\\mathbf{v}_i$ is an eigenvector of $P$ then $P\\mathbf{v}_i = \\lambda_i \\mathbf{v}_i$, and\n",
    "\n",
    "\\begin{align*}\n",
    "    X P \\mathbf{v}_i &= \\lambda_i X \\mathbf{v}_i\\\\\n",
    "    X X^T X \\mathbf{v}_i &= \\lambda_i X \\mathbf{v}_i\\\\\n",
    "    C X \\mathbf{v}_i &= \\lambda_i X \\mathbf{v}_i\n",
    "\\end{align*}\n",
    "\n",
    "If we let $\\mathbf{u}_i = X \\mathbf{v}_i$, then $\\mathbf{u}_i$ and $\\lambda_i$ are the 400 eigenvectors and eigenvalues of $C$.\n",
    "\n",
    "For reconstruction purposes, normalize each $\\mathbf{u}_i$ (or each eigenface).\n",
    "\n",
    "**Fill in the function below. It should return the eigenfaces and weights of your dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images, height, width = images.shape\n",
    "\n",
    "def compute_pca(data, data_mean):\n",
    "    # 1. Subtract the mean image from all images\n",
    "\n",
    "    # 2. Vectorize the images to a 400 x 10304 matrix -- use reshape\n",
    "\n",
    "    # 3. Create the covariance matrix -- don't forget to divide by 1 less than the number of samples\n",
    "\n",
    "    # 4. Compute the eigendecomposition -- try np.linalg.eig\n",
    "\n",
    "    # 5. Calculate the eigenfaces: U = XV -- you may have to multiply these differently based on the shape\n",
    "\n",
    "    # 6. Normalize the eigenfaces to that they are unit vectors -- np.lingalg.norm helps here!\n",
    "    \n",
    "    # 7. Compute the weights by projected the centered data onto the eigenfaces\n",
    "    \n",
    "    # 8. Return the normalized eigenfaces and weights\n",
    "    return eigenfaces, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609323d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA and visualize\n",
    "eigenfaces, weights = compute_pca(images, face_mean)\n",
    "\n",
    "# Visualize some eigenfaces\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(4, 4), axes_pad=0)\n",
    "\n",
    "for ax, im in zip(grid, eigenfaces[:16]):\n",
    "    ax.imshow(im.reshape(height, width))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6a967",
   "metadata": {},
   "source": [
    "# Eigenfaces as a form of compression\n",
    "\n",
    "We can reconstruct the original images from the eigenfaces. This is accomplished by taking the mean image of the dataset and adding the eigenfaces scaled by the weights calculated in `compute_pca`:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbf{x}_{r} = \\mathbf{x}_{mean} + \\sum_{i=0}^{M-1} w_{i}\\mathbf{u}_i\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(weights, eigenfaces, X_mean, img_size, img_idx, n_comps=400):\n",
    "    \"\"\"TODO: Reconstruct the image given by `img_idx` using `n_comps` eigenfaces.\n",
    "    Don't forget to reshape the image so that it is no longer a vector!\n",
    "    \"\"\"\n",
    "    return recovered_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a7092",
   "metadata": {},
   "source": [
    "# Visualizing the Reconstruction\n",
    "\n",
    "Congratulations! You've made it! The last step is to check out your work by visualizing how good the reconstructed image is based on the number of eigenfaces used during reconstruction. Play around with `img_idx` and `n_comps` below to select a different image and different number of principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 200\n",
    "n_comps = 400\n",
    "\n",
    "recovered_img = reconstruct(weights, eigenfaces, face_mean.reshape(-1), [height, width], img_idx, n_comps)\n",
    "\n",
    "# Visualize original and reconstructed\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax1.imshow(images[img_idx])\n",
    "ax2.imshow(recovered_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
